# Bits-and-Byes

Bits-and-Byes is a library for efficient quantization and memory optimization in PyTorch, designed to make large language models and deep learning more accessible.

## Features

- 8-bit and 4-bit quantization primitives for PyTorch
- Memory-efficient optimizers with block-wise quantization
- LLM.int8() inference with minimal performance degradation
- QLoRA-style fine-tuning for large language models
- Cross-platform support for various hardware accelerators

## Project Status

⚠️ **Early Development** - This project is currently in the initial planning and development phase.

## Getting Started

See the [TODO.md](TODO.md) file for the project roadmap and current development status.

Detailed elaborations for major tasks:
- [Initial Setup and Project Structure](task1_initial_setup.md)
- [Core Library Foundation](task2_core_library.md)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

This project is inspired by the [bitsandbytes](https://github.com/bitsandbytes-foundation/bitsandbytes) library. 
