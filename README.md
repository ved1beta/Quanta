# Quanta ğŸš€

A lightweight PyTorch library for efficient model quantization and memory optimization. Perfect for running large language models on consumer hardware.

## Key Features

- ğŸ¯ 8-bit & 4-bit quantization primitives
- ğŸ’¾ Memory-efficient optimizers
- ğŸš€ LLM.int8() inference support
- ğŸ”„ QLoRA-style fine-tuning
- ğŸ–¥ï¸ Cross-platform hardware support

## Quick Start

```python
import torch
from bytesandbits.functional.quantization import quantize_8bit, dequantize_8bit

# Quantize your model
q_tensor, scale, zero_point = quantize_8bit(model_weights)
```

## Status

ğŸš§ Early Development - Currently implementing core quantization features.

## License

MIT License

Inspired by [bitsandbytes](https://github.com/bitsandbytes-foundation/bitsandbytes)
